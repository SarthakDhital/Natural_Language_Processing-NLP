{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nepali News Classification\n",
    "## Using Kaggle Dataset with ML & BERT Models\n",
    "\n",
    "**BUS 405: Foundations of Big Data Analytics**\n",
    "\n",
    "---\n",
    "\n",
    "### Dataset: Nepali News Dataset from Kaggle\n",
    "- **Source**: https://www.kaggle.com/datasets/lotusacharya/nepalinewsdataset\n",
    "- **Categories**: 10 news categories\n",
    "- **Size**: ~10,000 articles (1000 per category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers torch scikit-learn pandas matplotlib seaborn kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set seeds\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Dataset from Kaggle\n",
    "\n",
    "### Option A: Using kagglehub (Easiest - Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 1: Using kagglehub (Recommended)\n",
    "import kagglehub\n",
    "\n",
    "# Download the dataset - this returns the path to the downloaded folder\n",
    "dataset_path = kagglehub.dataset_download(\"lotusacharya/nepalinewsdataset\")\n",
    "\n",
    "print(f\"Dataset downloaded to: {dataset_path}\")\n",
    "\n",
    "# List files in the downloaded folder\n",
    "print(\"\\nFiles in dataset folder:\")\n",
    "for item in os.listdir(dataset_path):\n",
    "    item_path = os.path.join(dataset_path, item)\n",
    "    if os.path.isfile(item_path):\n",
    "        size = os.path.getsize(item_path) / 1024  # KB\n",
    "        print(f\"  üìÑ {item} ({size:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"  üìÅ {item}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 2: Using Kaggle API (Alternative)\n",
    "# Uncomment if kagglehub doesn't work\n",
    "\n",
    "# # First upload your kaggle.json\n",
    "# from google.colab import files\n",
    "# print(\"Upload your kaggle.json:\")\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# # Setup credentials\n",
    "# !mkdir -p ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# # Download dataset\n",
    "# !kaggle datasets download -d lotusacharya/nepalinewsdataset\n",
    "# !unzip -o nepalinewsdataset.zip -d ./nepalinewsdataset\n",
    "# dataset_path = \"./nepalinewsdataset\"\n",
    "\n",
    "# print(f\"Dataset downloaded to: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load the Dataset from Downloaded Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find CSV file in the downloaded folder\n",
    "def find_csv_file(folder_path):\n",
    "    \"\"\"\n",
    "    Find CSV file in the downloaded Kaggle folder.\n",
    "    \"\"\"\n",
    "    # Search for CSV files\n",
    "    csv_files = glob.glob(os.path.join(folder_path, '**', '*.csv'), recursive=True)\n",
    "    \n",
    "    if csv_files:\n",
    "        print(f\"Found {len(csv_files)} CSV file(s):\")\n",
    "        for f in csv_files:\n",
    "            print(f\"  - {f}\")\n",
    "        return csv_files[0]  # Return the first one\n",
    "    else:\n",
    "        # Try direct file names\n",
    "        possible_names = ['nepali_news.csv', 'news.csv', 'data.csv', 'nepalinewsdataset.csv']\n",
    "        for name in possible_names:\n",
    "            path = os.path.join(folder_path, name)\n",
    "            if os.path.exists(path):\n",
    "                return path\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Find the CSV file\n",
    "csv_file = find_csv_file(dataset_path)\n",
    "\n",
    "if csv_file:\n",
    "    print(f\"\\n‚úÖ Using CSV file: {csv_file}\")\n",
    "else:\n",
    "    print(\"‚ùå No CSV file found!\")\n",
    "    print(\"\\nContents of dataset folder:\")\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            print(f\"  {os.path.join(root, file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded!\")\n",
    "print(f\"   Shape: {df.shape}\")\n",
    "print(f\"   Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names\n",
    "print(\"Original columns:\", df.columns.tolist())\n",
    "\n",
    "# Rename columns to standard names\n",
    "# The Nepali News Dataset typically has columns like: 'news'/'content' and 'category'\n",
    "rename_map = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower().strip()\n",
    "    if col_lower in ['news', 'content', 'article', 'body', 'text', 'headline']:\n",
    "        rename_map[col] = 'text'\n",
    "    elif col_lower in ['category', 'label', 'class', 'type', 'target']:\n",
    "        rename_map[col] = 'category'\n",
    "\n",
    "if rename_map:\n",
    "    df = df.rename(columns=rename_map)\n",
    "    print(f\"Renamed: {rename_map}\")\n",
    "\n",
    "print(f\"Final columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Check required columns exist\n",
    "if 'text' not in df.columns or 'category' not in df.columns:\n",
    "    print(\"\\n‚ö†Ô∏è Could not find 'text' and 'category' columns automatically.\")\n",
    "    print(\"Available columns:\", df.columns.tolist())\n",
    "    print(\"\\nPlease manually set the column names below:\")\n",
    "    # Manual override - uncomment and modify as needed\n",
    "    # df = df.rename(columns={'YOUR_TEXT_COLUMN': 'text', 'YOUR_CATEGORY_COLUMN': 'category'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Number of categories: {df['category'].nunique()}\")\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values\n",
    "df = df.dropna(subset=['text', 'category'])\n",
    "print(f\"After removing nulls: {len(df)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category distribution\n",
    "print(\"\\nCategory Distribution:\")\n",
    "print(df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categories\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = df['category'].value_counts().plot(kind='barh', color='steelblue')\n",
    "plt.title('Nepali News Category Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Category')\n",
    "\n",
    "# Add count labels\n",
    "for i, v in enumerate(df['category'].value_counts()):\n",
    "    ax.text(v + 10, i, str(v), va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text from each category\n",
    "print(\"\\nSample news from each category:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for cat in df['category'].unique():\n",
    "    sample = df[df['category'] == cat]['text'].iloc[0]\n",
    "    sample_text = str(sample)[:100] + \"...\" if len(str(sample)) > 100 else str(sample)\n",
    "    print(f\"\\nüì∞ [{cat}]\")\n",
    "    print(f\"   {sample_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nepali_text(text):\n",
    "    \"\"\"\n",
    "    Clean Nepali text for classification.\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'[0-9‡•¶-‡•Ø]+', '', text)\n",
    "    \n",
    "    # Keep only Devanagari characters and spaces\n",
    "    text = re.sub(r'[^\\u0900-\\u097F\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"Preprocessing text...\")\n",
    "df['clean_text'] = df['text'].apply(preprocess_nepali_text)\n",
    "\n",
    "# Show example\n",
    "print(\"\\nExample:\")\n",
    "print(f\"Original: {str(df['text'].iloc[0])[:80]}...\")\n",
    "print(f\"Cleaned:  {df['clean_text'].iloc[0][:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove short texts\n",
    "df = df[df['clean_text'].str.len() >= 20]\n",
    "print(f\"After removing short texts: {len(df)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['category'])\n",
    "\n",
    "print(\"Label Encoding:\")\n",
    "for i, cat in enumerate(label_encoder.classes_):\n",
    "    count = (df['label'] == i).sum()\n",
    "    print(f\"  {i}: {cat} ({count} samples)\")\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"\\nTotal classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = df['clean_text'].values\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training: {len(X_train)} samples\")\n",
    "print(f\"Test: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Traditional ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF features\n",
    "print(\"Creating TF-IDF features...\")\n",
    "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), min_df=2)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"TF-IDF shape: {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'SVM': LinearSVC(random_state=RANDOM_SEED, max_iter=2000),\n",
    "    'Logistic Regression': LogisticRegression(random_state=RANDOM_SEED, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED, n_jobs=-1)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING ML MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n‚ñ∂ Training {name}...\")\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    results[name] = {'accuracy': acc, 'f1_score': f1, 'model': model}\n",
    "    print(f\"  Accuracy: {acc:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "results_df = pd.DataFrame({k: {'Accuracy': v['accuracy'], 'F1': v['f1_score']} \n",
    "                           for k, v in results.items()}).T\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, results_df['Accuracy'], width, label='Accuracy', color='#2ecc71')\n",
    "ax.bar(x + width/2, results_df['F1'], width, label='F1 Score', color='#3498db')\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('ML Models Performance', fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(results_df.index, rotation=15)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "for i, (acc, f1) in enumerate(zip(results_df['Accuracy'], results_df['F1'])):\n",
    "    ax.text(i - width/2, acc + 0.02, f'{acc:.3f}', ha='center', fontsize=9)\n",
    "    ax.text(i + width/2, f1 + 0.02, f'{f1:.3f}', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model report\n",
    "best_name = max(results, key=lambda x: results[x]['accuracy'])\n",
    "best_model = results[best_name]['model']\n",
    "y_pred_best = best_model.predict(X_test_tfidf)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"BEST MODEL: {best_name}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Accuracy: {results[best_name]['accuracy']:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_best, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title(f'Confusion Matrix - {best_name}', fontweight='bold')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Deep Learning with mBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "SAMPLE_SIZE = min(3000, len(df))  # Use sample for faster training\n",
    "\n",
    "print(f\"BERT Config: MAX_LENGTH={MAX_LENGTH}, BATCH_SIZE={BATCH_SIZE}, EPOCHS={EPOCHS}\")\n",
    "print(f\"Using {SAMPLE_SIZE} samples for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mBERT tokenizer\n",
    "print(\"Loading mBERT...\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "print(\"‚úÖ Tokenizer loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class NepaliDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer.encode_plus(\n",
    "            str(self.texts[idx]),\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': enc['input_ids'].flatten(),\n",
    "            'attention_mask': enc['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare BERT data\n",
    "df_bert = df.sample(n=SAMPLE_SIZE, random_state=RANDOM_SEED)\n",
    "X_b, y_b = df_bert['clean_text'].values, df_bert['label'].values\n",
    "\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "    X_b, y_b, test_size=0.2, random_state=RANDOM_SEED, stratify=y_b\n",
    ")\n",
    "X_train_b, X_val_b, y_train_b, y_val_b = train_test_split(\n",
    "    X_train_b, y_train_b, test_size=0.1, random_state=RANDOM_SEED, stratify=y_train_b\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train_b)}, Val: {len(X_val_b)}, Test: {len(X_test_b)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_ds = NepaliDataset(X_train_b, y_train_b, tokenizer, MAX_LENGTH)\n",
    "val_ds = NepaliDataset(X_val_b, y_val_b, tokenizer, MAX_LENGTH)\n",
    "test_ds = NepaliDataset(X_test_b, y_test_b, tokenizer, MAX_LENGTH)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Batches - Train: {len(train_loader)}, Val: {len(val_loader)}, Test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mBERT model\n",
    "print(\"Loading mBERT model...\")\n",
    "bert_model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-multilingual-cased', num_labels=num_classes\n",
    ").to(device)\n",
    "print(f\"‚úÖ Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(bert_model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=len(train_loader)*EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions\n",
    "def train_epoch(model, loader, opt, sched):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for batch in tqdm(loader, desc='Training'):\n",
    "        opt.zero_grad()\n",
    "        outputs = model(\n",
    "            input_ids=batch['input_ids'].to(device),\n",
    "            attention_mask=batch['attention_mask'].to(device),\n",
    "            labels=batch['labels'].to(device)\n",
    "        )\n",
    "        outputs.loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        sched.step()\n",
    "        total_loss += outputs.loss.item()\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        correct += (preds == batch['labels'].to(device)).sum().item()\n",
    "        total += batch['labels'].size(0)\n",
    "    return total_loss/len(loader), correct/total\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Evaluating'):\n",
    "            outputs = model(\n",
    "                input_ids=batch['input_ids'].to(device),\n",
    "                attention_mask=batch['attention_mask'].to(device),\n",
    "                labels=batch['labels'].to(device)\n",
    "            )\n",
    "            total_loss += outputs.loss.item()\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            correct += (preds == batch['labels'].to(device)).sum().item()\n",
    "            total += batch['labels'].size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch['labels'].numpy())\n",
    "    return total_loss/len(loader), correct/total, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train mBERT\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING mBERT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_val_acc = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    train_loss, train_acc = train_epoch(bert_model, train_loader, optimizer, scheduler)\n",
    "    val_loss, val_acc, _, _ = evaluate(bert_model, val_loader)\n",
    "    print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(bert_model.state_dict(), 'best_mbert.pt')\n",
    "        print(\"  ‚úì Saved best model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test mBERT\n",
    "bert_model.load_state_dict(torch.load('best_mbert.pt'))\n",
    "test_loss, test_acc, y_pred_bert, y_true_bert = evaluate(bert_model, test_loader)\n",
    "bert_f1 = f1_score(y_true_bert, y_pred_bert, average='weighted')\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"mBERT TEST RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Accuracy: {test_acc:.4f}\")\n",
    "print(f\"F1 Score: {bert_f1:.4f}\")\n",
    "\n",
    "results['mBERT'] = {'accuracy': test_acc, 'f1_score': bert_f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_df = pd.DataFrame({\n",
    "    k: {'Accuracy': v['accuracy'], 'F1': v['f1_score']} \n",
    "    for k, v in results.items() if 'accuracy' in v\n",
    "}).T.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(final_df))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, final_df['Accuracy'], width, label='Accuracy', color='#27ae60')\n",
    "plt.bar(x + width/2, final_df['F1'], width, label='F1 Score', color='#3498db')\n",
    "\n",
    "plt.ylabel('Score')\n",
    "plt.title('All Models Comparison - Nepali News Classification', fontweight='bold')\n",
    "plt.xticks(x, final_df.index, rotation=15)\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "for i, (acc, f1) in enumerate(zip(final_df['Accuracy'], final_df['F1'])):\n",
    "    plt.text(i - width/2, acc + 0.02, f'{acc:.3f}', ha='center', fontsize=9)\n",
    "    plt.text(i + width/2, f1 + 0.02, f'{f1:.3f}', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, use_bert=False):\n",
    "    \"\"\"Predict category for Nepali news text.\"\"\"\n",
    "    clean = preprocess_nepali_text(text)\n",
    "    \n",
    "    if use_bert:\n",
    "        enc = tokenizer.encode_plus(clean, max_length=MAX_LENGTH, \n",
    "                                    padding='max_length', truncation=True, return_tensors='pt')\n",
    "        bert_model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = bert_model(input_ids=enc['input_ids'].to(device),\n",
    "                           attention_mask=enc['attention_mask'].to(device))\n",
    "            pred = torch.argmax(out.logits, dim=1).cpu().item()\n",
    "    else:\n",
    "        feat = tfidf.transform([clean])\n",
    "        pred = best_model.predict(feat)[0]\n",
    "    \n",
    "    return label_encoder.inverse_transform([pred])[0]\n",
    "\n",
    "# Test\n",
    "test_texts = [\n",
    "    \"‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§®‡•ç‡§§‡•ç‡§∞‡•Ä‡§≤‡•á ‡§∏‡§Ç‡§∏‡§¶‡§Æ‡§æ ‡§®‡§Ø‡§æ‡§Å ‡§®‡•Ä‡§§‡§ø ‡§ò‡•ã‡§∑‡§£‡§æ ‡§ó‡§∞‡•á‡•§\",\n",
    "    \"‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§ï‡•ç‡§∞‡§ø‡§ï‡•á‡§ü ‡§ü‡•ã‡§≤‡•Ä‡§≤‡•á ‡§µ‡§ø‡§∂‡•ç‡§µ‡§ï‡§™‡§Æ‡§æ ‡§ú‡§ø‡§§ ‡§π‡§æ‡§∏‡§ø‡§≤ ‡§ó‡§∞‡•ç‡§Ø‡•ã‡•§\",\n",
    "    \"‡§∂‡•á‡§Ø‡§∞ ‡§¨‡§ú‡§æ‡§∞‡§Æ‡§æ ‡§Ü‡§ú ‡§â‡§≤‡•ç‡§≤‡•á‡§ñ‡•ç‡§Ø ‡§ó‡§ø‡§∞‡§æ‡§µ‡§ü ‡§Ü‡§Ø‡•ã‡•§\"\n",
    "]\n",
    "\n",
    "print(\"\\nPredictions:\")\n",
    "for text in test_texts:\n",
    "    pred = predict(text)\n",
    "    print(f\"  '{text[:50]}...' ‚Üí {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ NOTEBOOK COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset: {len(df)} Nepali news articles\")\n",
    "print(f\"Categories: {num_classes}\")\n",
    "print(f\"Best ML: {best_name} ({results[best_name]['accuracy']:.2%})\")\n",
    "print(f\"mBERT: {test_acc:.2%}\")\n",
    "print(\"\\nüá≥üáµ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
