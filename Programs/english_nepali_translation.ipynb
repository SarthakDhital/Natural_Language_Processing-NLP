{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eluMWhyXulI"
      },
      "source": [
        "# English to Nepali Translation with Transformer Models\n",
        "## Using mBART-50, NLLB-200 & Understanding mBERT Limitations\n",
        "\n",
        "**BUS 405: Foundations of Big Data Analytics**\n",
        "\n",
        "---\n",
        "\n",
        "## Important: Why NOT mBERT or RoBERTa for Translation?\n",
        "\n",
        "### ‚ùå mBERT and RoBERTa are NOT translation models!\n",
        "\n",
        "| Model | Architecture | Purpose | Can Translate? |\n",
        "|-------|--------------|---------|----------------|\n",
        "| **mBERT** | Encoder-only | Understanding multilingual text | ‚ùå No |\n",
        "| **XLM-RoBERTa** | Encoder-only | Cross-lingual understanding | ‚ùå No |\n",
        "| **mBART-50** | Encoder-Decoder | Multilingual translation | ‚úÖ Yes |\n",
        "| **NLLB-200** | Encoder-Decoder | 200+ language translation | ‚úÖ Yes |\n",
        "\n",
        "### Why Encoder-Only Models Can't Translate:\n",
        "- **mBERT/RoBERTa** are trained to **understand** text, not **generate** it\n",
        "- They produce **embeddings**, not **translated sentences**\n",
        "- Translation requires an **encoder-decoder** architecture\n",
        "\n",
        "### What mBERT/RoBERTa ARE Good For:\n",
        "- Cross-lingual text classification\n",
        "- Multilingual named entity recognition (NER)\n",
        "- Cross-lingual similarity/search\n",
        "- Multilingual question answering\n",
        "\n",
        "---\n",
        "\n",
        "In this notebook, we will:\n",
        "1. Demonstrate why mBERT can't translate (and what it does instead)\n",
        "2. Use **mBART-50** for English ‚Üí Nepali translation\n",
        "3. Use **NLLB-200** for English ‚Üí Nepali translation\n",
        "4. Compare translation quality\n",
        "5. Build a complete English-Nepali translator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_Ktk7WRXulK"
      },
      "source": [
        "## 1. Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTXZPu4QXulL"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers torch sentencepiece protobuf accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjOe62znXulM"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from transformers import (\n",
        "    # mBERT (for demonstration of what it can/cannot do)\n",
        "    BertModel,\n",
        "    BertTokenizer,\n",
        "\n",
        "    # mBART-50 for translation\n",
        "    MBartForConditionalGeneration,\n",
        "    MBart50TokenizerFast,\n",
        "\n",
        "    # NLLB for translation\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "\n",
        "    # Pipeline for easy use\n",
        "    pipeline\n",
        ")\n",
        "\n",
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLE8A5SNXulN"
      },
      "source": [
        "## 2. Why mBERT Cannot Translate (Demonstration)\n",
        "\n",
        "Let's see what mBERT actually does - it creates **embeddings**, not translations!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJUqVvhXXulN"
      },
      "outputs": [],
      "source": [
        "# Load mBERT (Multilingual BERT)\n",
        "print(\"Loading mBERT...\")\n",
        "mbert_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "mbert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "print(\"mBERT loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg6BtpegXulN"
      },
      "outputs": [],
      "source": [
        "# Demonstrate what mBERT outputs\n",
        "print(\"=\"*70)\n",
        "print(\"WHAT mBERT ACTUALLY DOES (NOT Translation!)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "english_text = \"Hello, how are you?\"\n",
        "\n",
        "# Tokenize and get embeddings\n",
        "inputs = mbert_tokenizer(english_text, return_tensors='pt')\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = mbert_model(**inputs)\n",
        "\n",
        "print(f\"\\nInput text: '{english_text}'\")\n",
        "print(f\"\\nmBERT Output Shape: {outputs.last_hidden_state.shape}\")\n",
        "print(f\"  - Batch size: {outputs.last_hidden_state.shape[0]}\")\n",
        "print(f\"  - Sequence length: {outputs.last_hidden_state.shape[1]}\")\n",
        "print(f\"  - Hidden dimension: {outputs.last_hidden_state.shape[2]}\")\n",
        "\n",
        "print(\"\\n‚ùå mBERT outputs EMBEDDINGS (numbers), NOT translated text!\")\n",
        "print(\"‚ùå There is NO way to get '‡§§‡§™‡§æ‡§à‡§Ç‡§≤‡§æ‡§à ‡§ï‡§∏‡•ç‡§§‡•ã ‡§õ?' from these embeddings directly!\")\n",
        "print(\"\\nüí° For translation, we need ENCODER-DECODER models like mBART or NLLB.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jf46qncUXulO"
      },
      "outputs": [],
      "source": [
        "# What mBERT IS good for: Cross-lingual similarity\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"WHAT mBERT IS GOOD FOR: Cross-lingual Similarity\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Same meaning in different languages\n",
        "texts = [\n",
        "    \"Hello, how are you?\",           # English\n",
        "    \"‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§§‡§™‡§æ‡§à‡§Ç‡§≤‡§æ‡§à ‡§ï‡§∏‡•ç‡§§‡•ã ‡§õ?\",        # Nepali\n",
        "    \"Bonjour, comment allez-vous?\",   # French\n",
        "    \"I love pizza.\"                   # Different meaning\n",
        "]\n",
        "\n",
        "def get_sentence_embedding(text):\n",
        "    \"\"\"Get sentence embedding using [CLS] token.\"\"\"\n",
        "    inputs = mbert_tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = mbert_model(**inputs)\n",
        "    # Use [CLS] token embedding\n",
        "    return outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "# Get embeddings\n",
        "embeddings = [get_sentence_embedding(text) for text in texts]\n",
        "\n",
        "# Calculate cosine similarity\n",
        "from torch.nn.functional import cosine_similarity\n",
        "\n",
        "print(\"\\nCosine Similarity between sentences:\")\n",
        "print(\"-\"*70)\n",
        "print(f\"English vs Nepali (same meaning):  {cosine_similarity(embeddings[0], embeddings[1]).item():.4f}\")\n",
        "print(f\"English vs French (same meaning):  {cosine_similarity(embeddings[0], embeddings[2]).item():.4f}\")\n",
        "print(f\"English vs 'I love pizza' (diff):  {cosine_similarity(embeddings[0], embeddings[3]).item():.4f}\")\n",
        "\n",
        "print(\"\\n‚úÖ mBERT understands that sentences with SAME meaning are similar!\")\n",
        "print(\"‚úÖ This is useful for cross-lingual search, classification, etc.\")\n",
        "print(\"‚ùå But it still cannot GENERATE translations!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXEaifz2XulO"
      },
      "source": [
        "## 3. mBART-50: English to Nepali Translation\n",
        "\n",
        "**mBART-50** is a multilingual translation model that supports **50 languages including Nepali**!\n",
        "\n",
        "Nepali language code: `ne_NP`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZqN755OXulO"
      },
      "outputs": [],
      "source": [
        "# Load mBART-50 model\n",
        "print(\"Loading mBART-50 (this may take a minute)...\")\n",
        "\n",
        "mbart_model = MBartForConditionalGeneration.from_pretrained(\n",
        "    \"facebook/mbart-large-50-one-to-many-mmt\"\n",
        ")\n",
        "mbart_tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "    \"facebook/mbart-large-50-one-to-many-mmt\",\n",
        "    src_lang=\"en_XX\"  # Source language is English\n",
        ")\n",
        "\n",
        "# Move to GPU if available\n",
        "mbart_model = mbart_model.to(device)\n",
        "\n",
        "print(\"mBART-50 loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTJzI0RpXulP"
      },
      "outputs": [],
      "source": [
        "# Check supported languages in mBART-50\n",
        "print(\"mBART-50 Supported Languages (50 languages):\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Some key languages\n",
        "mbart_languages = {\n",
        "    'en_XX': 'English',\n",
        "    'ne_NP': 'Nepali',\n",
        "    'hi_IN': 'Hindi',\n",
        "    'bn_IN': 'Bengali',\n",
        "    'zh_CN': 'Chinese',\n",
        "    'ja_XX': 'Japanese',\n",
        "    'ko_KR': 'Korean',\n",
        "    'fr_XX': 'French',\n",
        "    'de_DE': 'German',\n",
        "    'es_XX': 'Spanish',\n",
        "    'ar_AR': 'Arabic',\n",
        "    'ru_RU': 'Russian'\n",
        "}\n",
        "\n",
        "for code, name in mbart_languages.items():\n",
        "    print(f\"  {code}: {name}\")\n",
        "\n",
        "print(\"\\n‚úÖ Nepali (ne_NP) is supported!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDlFZyowXulP"
      },
      "outputs": [],
      "source": [
        "def translate_with_mbart(text, target_lang=\"ne_NP\"):\n",
        "    \"\"\"\n",
        "    Translate English text to target language using mBART-50.\n",
        "\n",
        "    Args:\n",
        "        text: English text to translate\n",
        "        target_lang: Target language code (default: ne_NP for Nepali)\n",
        "\n",
        "    Returns:\n",
        "        Translated text\n",
        "    \"\"\"\n",
        "    # Tokenize\n",
        "    inputs = mbart_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Generate translation\n",
        "    with torch.no_grad():\n",
        "        generated_tokens = mbart_model.generate(\n",
        "            **inputs,\n",
        "            forced_bos_token_id=mbart_tokenizer.lang_code_to_id[target_lang],\n",
        "            max_length=128,\n",
        "            num_beams=5,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "    # Decode\n",
        "    translation = mbart_tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
        "    return translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI6WpHdSXulP"
      },
      "outputs": [],
      "source": [
        "# Test English to Nepali translation with mBART\n",
        "print(\"=\"*70)\n",
        "print(\"ENGLISH TO NEPALI TRANSLATION (mBART-50)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "english_sentences = [\n",
        "    \"Hello, how are you?\",\n",
        "    \"My name is Ram.\",\n",
        "    \"Nepal is a beautiful country.\",\n",
        "    \"I love Nepali food.\",\n",
        "    \"Mount Everest is in Nepal.\",\n",
        "    \"Good morning!\",\n",
        "    \"Thank you very much.\",\n",
        "    \"What is your name?\",\n",
        "    \"The weather is nice today.\",\n",
        "    \"I am learning Nepali language.\"\n",
        "]\n",
        "\n",
        "print(\"\\nüá¨üáß English ‚Üí üá≥üáµ Nepali Translations:\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "for sentence in english_sentences:\n",
        "    nepali = translate_with_mbart(sentence, \"ne_NP\")\n",
        "    print(f\"üá¨üáß {sentence}\")\n",
        "    print(f\"üá≥üáµ {nepali}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7JXl31mXulP"
      },
      "source": [
        "## 4. NLLB-200: English to Nepali Translation\n",
        "\n",
        "**NLLB (No Language Left Behind)** by Meta supports **200+ languages** with high quality, especially for low-resource languages like Nepali.\n",
        "\n",
        "Nepali language code in NLLB: `npi_Deva` (Nepali in Devanagari script)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMTSTe1aXulP"
      },
      "outputs": [],
      "source": [
        "# Load NLLB model (smaller distilled version)\n",
        "print(\"Loading NLLB-200 (distilled 600M)...\")\n",
        "\n",
        "nllb_model_name = \"facebook/nllb-200-distilled-600M\"\n",
        "nllb_tokenizer = AutoTokenizer.from_pretrained(nllb_model_name)\n",
        "nllb_model = AutoModelForSeq2SeqLM.from_pretrained(nllb_model_name)\n",
        "\n",
        "# Move to GPU if available\n",
        "nllb_model = nllb_model.to(device)\n",
        "\n",
        "print(\"NLLB-200 loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_rr5aYwXulQ"
      },
      "outputs": [],
      "source": [
        "def translate_with_nllb(text, src_lang=\"eng_Latn\", tgt_lang=\"npi_Deva\"):\n",
        "    \"\"\"\n",
        "    Translate text using NLLB-200.\n",
        "\n",
        "    Args:\n",
        "        text: Text to translate\n",
        "        src_lang: Source language code (default: eng_Latn for English)\n",
        "        tgt_lang: Target language code (default: npi_Deva for Nepali)\n",
        "\n",
        "    Returns:\n",
        "        Translated text\n",
        "    \"\"\"\n",
        "    # Set source language\n",
        "    nllb_tokenizer.src_lang = src_lang\n",
        "\n",
        "    # Tokenize\n",
        "    inputs = nllb_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Generate translation\n",
        "    with torch.no_grad():\n",
        "        generated_tokens = nllb_model.generate(\n",
        "            **inputs,\n",
        "            forced_bos_token_id=nllb_tokenizer.convert_tokens_to_ids(tgt_lang),\n",
        "            max_length=128,\n",
        "            num_beams=5,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "    # Decode\n",
        "    translation = nllb_tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
        "    return translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoHmDNVVXulQ"
      },
      "outputs": [],
      "source": [
        "# Test English to Nepali translation with NLLB\n",
        "print(\"=\"*70)\n",
        "print(\"ENGLISH TO NEPALI TRANSLATION (NLLB-200)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nüá¨üáß English ‚Üí üá≥üáµ Nepali Translations:\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "for sentence in english_sentences:\n",
        "    nepali = translate_with_nllb(sentence)\n",
        "    print(f\"üá¨üáß {sentence}\")\n",
        "    print(f\"üá≥üáµ {nepali}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLSK1wSAXulQ"
      },
      "source": [
        "## 5. Compare mBART vs NLLB Translations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zuxkt7_BXulQ"
      },
      "outputs": [],
      "source": [
        "# Side-by-side comparison\n",
        "print(\"=\"*70)\n",
        "print(\"COMPARISON: mBART-50 vs NLLB-200\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "comparison_sentences = [\n",
        "    \"Hello, how are you?\",\n",
        "    \"Nepal is a beautiful country in the Himalayas.\",\n",
        "    \"I am learning to speak Nepali.\",\n",
        "    \"The food is very delicious.\",\n",
        "    \"Where is the nearest hospital?\"\n",
        "]\n",
        "\n",
        "print(\"\\n{:<40} | {:<40} | {:<40}\".format(\"English\", \"mBART-50\", \"NLLB-200\"))\n",
        "print(\"-\"*125)\n",
        "\n",
        "for sentence in comparison_sentences:\n",
        "    mbart_trans = translate_with_mbart(sentence, \"ne_NP\")\n",
        "    nllb_trans = translate_with_nllb(sentence)\n",
        "\n",
        "    print(f\"\\nüá¨üáß {sentence}\")\n",
        "    print(f\"   mBART: {mbart_trans}\")\n",
        "    print(f\"   NLLB:  {nllb_trans}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufpMCx0jXulQ"
      },
      "source": [
        "## 6. Complete English-Nepali Translator Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rj1l1k6-XulQ"
      },
      "outputs": [],
      "source": [
        "class EnglishNepaliTranslator:\n",
        "    \"\"\"\n",
        "    A complete English to Nepali translator using multiple models.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_type='nllb'):\n",
        "        \"\"\"\n",
        "        Initialize translator.\n",
        "\n",
        "        Args:\n",
        "            model_type: 'nllb' or 'mbart'\n",
        "        \"\"\"\n",
        "        self.model_type = model_type\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        if model_type == 'nllb':\n",
        "            print(\"Loading NLLB-200...\")\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
        "            self.model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
        "            self.src_lang = \"eng_Latn\"\n",
        "            self.tgt_lang = \"npi_Deva\"\n",
        "        else:\n",
        "            print(\"Loading mBART-50...\")\n",
        "            self.tokenizer = MBart50TokenizerFast.from_pretrained(\n",
        "                \"facebook/mbart-large-50-one-to-many-mmt\",\n",
        "                src_lang=\"en_XX\"\n",
        "            )\n",
        "            self.model = MBartForConditionalGeneration.from_pretrained(\n",
        "                \"facebook/mbart-large-50-one-to-many-mmt\"\n",
        "            )\n",
        "            self.tgt_lang = \"ne_NP\"\n",
        "\n",
        "        self.model = self.model.to(self.device)\n",
        "        print(f\"Translator ready! Using {model_type.upper()}\")\n",
        "\n",
        "    def translate(self, text, num_beams=5, max_length=128):\n",
        "        \"\"\"\n",
        "        Translate English text to Nepali.\n",
        "\n",
        "        Args:\n",
        "            text: English text to translate\n",
        "            num_beams: Beam search width\n",
        "            max_length: Maximum output length\n",
        "\n",
        "        Returns:\n",
        "            Nepali translation\n",
        "        \"\"\"\n",
        "        if self.model_type == 'nllb':\n",
        "            self.tokenizer.src_lang = self.src_lang\n",
        "            inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = self.model.generate(\n",
        "                    **inputs,\n",
        "                    forced_bos_token_id=self.tokenizer.convert_tokens_to_ids(self.tgt_lang),\n",
        "                    max_length=max_length,\n",
        "                    num_beams=num_beams,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "        else:\n",
        "            inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = self.model.generate(\n",
        "                    **inputs,\n",
        "                    forced_bos_token_id=self.tokenizer.lang_code_to_id[self.tgt_lang],\n",
        "                    max_length=max_length,\n",
        "                    num_beams=num_beams,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "\n",
        "        return self.tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
        "\n",
        "    def translate_batch(self, texts):\n",
        "        \"\"\"\n",
        "        Translate multiple texts.\n",
        "        \"\"\"\n",
        "        return [self.translate(text) for text in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpVhVisEXulQ"
      },
      "outputs": [],
      "source": [
        "# Test the complete translator\n",
        "print(\"=\"*70)\n",
        "print(\"COMPLETE ENGLISH-NEPALI TRANSLATOR\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create translator (using NLLB)\n",
        "translator = EnglishNepaliTranslator(model_type='nllb')\n",
        "\n",
        "# Nepal-related sentences\n",
        "nepal_sentences = [\n",
        "    \"Kathmandu is the capital of Nepal.\",\n",
        "    \"Pokhara is famous for its beautiful lakes.\",\n",
        "    \"Mount Everest is the tallest mountain in the world.\",\n",
        "    \"Nepali people are very friendly and hospitable.\",\n",
        "    \"Dal Bhat is the traditional food of Nepal.\",\n",
        "    \"The Himalayan mountains are majestic.\",\n",
        "    \"Buddha was born in Lumbini, Nepal.\",\n",
        "    \"I want to visit Nepal someday.\"\n",
        "]\n",
        "\n",
        "print(\"\\nüá¨üáß English ‚Üí üá≥üáµ Nepali:\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "for sentence in nepal_sentences:\n",
        "    translation = translator.translate(sentence)\n",
        "    print(f\"üá¨üáß {sentence}\")\n",
        "    print(f\"üá≥üáµ {translation}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJfpADeNXulQ"
      },
      "source": [
        "## 7. Translation to Other South Asian Languages\n",
        "\n",
        "Both mBART and NLLB support other South Asian languages too!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KBFDPJBXulQ"
      },
      "outputs": [],
      "source": [
        "# Translate to multiple South Asian languages using NLLB\n",
        "print(\"=\"*70)\n",
        "print(\"ENGLISH TO SOUTH ASIAN LANGUAGES (NLLB)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "test_text = \"Nepal is a beautiful country.\"\n",
        "\n",
        "# NLLB language codes for South Asian languages\n",
        "south_asian_langs = {\n",
        "    'npi_Deva': 'üá≥üáµ Nepali',\n",
        "    'hin_Deva': 'üáÆüá≥ Hindi',\n",
        "    'ben_Beng': 'üáßüá© Bengali',\n",
        "    'urd_Arab': 'üáµüá∞ Urdu',\n",
        "    'tam_Taml': 'üáÆüá≥ Tamil',\n",
        "    'sin_Sinh': 'üá±üá∞ Sinhala'\n",
        "}\n",
        "\n",
        "print(f\"\\nOriginal (English): {test_text}\\n\")\n",
        "\n",
        "for lang_code, lang_name in south_asian_langs.items():\n",
        "    try:\n",
        "        translation = translate_with_nllb(test_text, tgt_lang=lang_code)\n",
        "        print(f\"{lang_name}: {translation}\")\n",
        "    except Exception as e:\n",
        "        print(f\"{lang_name}: Error - {str(e)[:30]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkzZgwOGXulQ"
      },
      "source": [
        "## 8. Interactive Translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlBcRGXsXulR"
      },
      "outputs": [],
      "source": [
        "def interactive_translator():\n",
        "    \"\"\"\n",
        "    Interactive English to Nepali translator.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"INTERACTIVE ENGLISH-NEPALI TRANSLATOR\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"Enter English text to translate to Nepali.\")\n",
        "    print(\"Type 'quit' to exit.\\n\")\n",
        "\n",
        "    while True:\n",
        "        text = input(\"üá¨üáß English: \")\n",
        "\n",
        "        if text.lower() == 'quit':\n",
        "            print(\"‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! (Thank you!)\")\n",
        "            break\n",
        "\n",
        "        if text.strip():\n",
        "            nepali = translator.translate(text)\n",
        "            print(f\"üá≥üáµ Nepali:  {nepali}\\n\")\n",
        "\n",
        "# Uncomment to run interactive translator\n",
        "# interactive_translator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trf_gOEsXulR"
      },
      "source": [
        "## 9. Common Nepali Phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VY7niXHOXulR"
      },
      "outputs": [],
      "source": [
        "# Common phrases translation\n",
        "print(\"=\"*70)\n",
        "print(\"COMMON ENGLISH-NEPALI PHRASES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "common_phrases = [\n",
        "    # Greetings\n",
        "    \"Hello\",\n",
        "    \"Good morning\",\n",
        "    \"Good night\",\n",
        "    \"How are you?\",\n",
        "    \"I am fine\",\n",
        "\n",
        "    # Basic\n",
        "    \"Thank you\",\n",
        "    \"You are welcome\",\n",
        "    \"Please\",\n",
        "    \"Sorry\",\n",
        "    \"Yes\",\n",
        "    \"No\",\n",
        "\n",
        "    # Questions\n",
        "    \"What is your name?\",\n",
        "    \"Where are you from?\",\n",
        "    \"How much does this cost?\",\n",
        "    \"Where is the bathroom?\",\n",
        "\n",
        "    # Useful\n",
        "    \"I don't understand\",\n",
        "    \"Can you help me?\",\n",
        "    \"I love Nepal\",\n",
        "    \"The food is delicious\",\n",
        "    \"See you later\"\n",
        "]\n",
        "\n",
        "print(\"\\n{:<35} | {}\".format(\"English\", \"Nepali\"))\n",
        "print(\"-\"*70)\n",
        "\n",
        "for phrase in common_phrases:\n",
        "    nepali = translator.translate(phrase)\n",
        "    print(f\"{phrase:<35} | {nepali}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEFOiDadXulR"
      },
      "source": [
        "## 10. Summary\n",
        "\n",
        "### Key Takeaways:\n",
        "\n",
        "| Model | Architecture | For Translation? | Nepali Support |\n",
        "|-------|--------------|------------------|----------------|\n",
        "| **mBERT** | Encoder-only | ‚ùå No | ‚úÖ Understanding |\n",
        "| **XLM-RoBERTa** | Encoder-only | ‚ùå No | ‚úÖ Understanding |\n",
        "| **mBART-50** | Encoder-Decoder | ‚úÖ Yes | ‚úÖ ne_NP |\n",
        "| **NLLB-200** | Encoder-Decoder | ‚úÖ Yes | ‚úÖ npi_Deva |\n",
        "\n",
        "### For English to Nepali Translation:\n",
        "1. **Use NLLB-200** - Best quality for low-resource languages\n",
        "2. **Use mBART-50** - Good alternative with 50 language support\n",
        "3. **Don't use mBERT/RoBERTa** - They can't generate translations!\n",
        "\n",
        "### Language Codes:\n",
        "- **mBART-50**: English = `en_XX`, Nepali = `ne_NP`\n",
        "- **NLLB-200**: English = `eng_Latn`, Nepali = `npi_Deva`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ct1VzS0uXulR"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ NOTEBOOK COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nYou have learned:\")\n",
        "print(\"  ‚úì Why mBERT/RoBERTa cannot translate (encoder-only)\")\n",
        "print(\"  ‚úì What mBERT is actually good for (cross-lingual similarity)\")\n",
        "print(\"  ‚úì Using mBART-50 for English-Nepali translation\")\n",
        "print(\"  ‚úì Using NLLB-200 for English-Nepali translation\")\n",
        "print(\"  ‚úì Building a complete translator class\")\n",
        "print(\"\\nüá≥üáµ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! (Thank you!)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}